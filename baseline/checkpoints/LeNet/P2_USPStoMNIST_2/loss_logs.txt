Begin training
Epoch:1, training loss:0.5843465328216553, test loss:0.7717623114585876, test acc:0.734
Epoch:2, training loss:0.27422842383384705, test loss:0.5114714503288269, test acc:0.8231
Epoch:3, training loss:0.24833440780639648, test loss:0.3972059190273285, test acc:0.8687
Epoch:4, training loss:0.12519516050815582, test loss:0.34989291429519653, test acc:0.8888
Epoch:5, training loss:0.10243719071149826, test loss:0.4968928396701813, test acc:0.8349
Epoch:6, training loss:0.12108898907899857, test loss:0.355940580368042, test acc:0.8887
Epoch:7, training loss:0.12709440290927887, test loss:0.43460413813591003, test acc:0.8579
Epoch:8, training loss:0.11151175945997238, test loss:0.28602591156959534, test acc:0.9129
Epoch:9, training loss:0.026546388864517212, test loss:0.33170777559280396, test acc:0.9003
Epoch:10, training loss:0.07057654112577438, test loss:0.31364715099334717, test acc:0.9088
Epoch:11, training loss:0.07706364244222641, test loss:0.3448473811149597, test acc:0.898
Epoch:12, training loss:0.02423710562288761, test loss:0.4719751477241516, test acc:0.8691
Epoch:13, training loss:0.15572747588157654, test loss:0.47251829504966736, test acc:0.8744
Epoch:14, training loss:0.05747430771589279, test loss:0.4527241289615631, test acc:0.8883
Epoch:15, training loss:0.03220391646027565, test loss:0.48466530442237854, test acc:0.874
Epoch:16, training loss:0.02051275223493576, test loss:0.48373040556907654, test acc:0.884
Epoch:17, training loss:0.02949005924165249, test loss:0.3410663306713104, test acc:0.9148
Epoch:18, training loss:0.009884183295071125, test loss:0.3901636600494385, test acc:0.9082
Epoch:19, training loss:0.024612121284008026, test loss:0.43338462710380554, test acc:0.9032
Epoch:20, training loss:0.029742339625954628, test loss:0.5344703793525696, test acc:0.8963
