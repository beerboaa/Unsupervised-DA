Begin training
Epoch:1, training loss:1.9019482135772705, test loss:1.6858313083648682, test acc:0.6016666666666667
Epoch:2, training loss:0.9169145822525024, test loss:0.8174414038658142, test acc:0.7216666666666667
Epoch:3, training loss:0.6091940402984619, test loss:0.6533111929893494, test acc:0.78
Epoch:4, training loss:0.5584657788276672, test loss:0.666595458984375, test acc:0.7766666666666666
Epoch:5, training loss:0.5871114134788513, test loss:0.6212896108627319, test acc:0.8144444444444444
Epoch:6, training loss:0.3707776367664337, test loss:0.617397665977478, test acc:0.7816666666666666
Epoch:7, training loss:0.5176588892936707, test loss:0.524175226688385, test acc:0.8127777777777778
Epoch:8, training loss:0.5032550096511841, test loss:0.5814500451087952, test acc:0.8216666666666667
Epoch:9, training loss:0.4592329263687134, test loss:0.7029013633728027, test acc:0.8138888888888889
Epoch:10, training loss:0.3822486996650696, test loss:0.638107180595398, test acc:0.8133333333333334
Epoch:11, training loss:0.3849898874759674, test loss:0.6210130453109741, test acc:0.7933333333333333
Epoch:12, training loss:0.326252818107605, test loss:0.4675150513648987, test acc:0.8338888888888889
Epoch:13, training loss:0.37372156977653503, test loss:0.44330012798309326, test acc:0.8577777777777778
Epoch:14, training loss:0.3493976593017578, test loss:0.7650050520896912, test acc:0.8172222222222222
Epoch:15, training loss:0.3033207654953003, test loss:0.6358375549316406, test acc:0.8438888888888889
Epoch:16, training loss:0.2523616552352905, test loss:0.6994497776031494, test acc:0.8222222222222222
Epoch:17, training loss:0.29953718185424805, test loss:0.5920001864433289, test acc:0.8
Epoch:18, training loss:0.3359265625476837, test loss:0.6064193248748779, test acc:0.8311111111111111
Epoch:19, training loss:0.27593815326690674, test loss:0.5359755754470825, test acc:0.8383333333333334
Epoch:20, training loss:0.26866936683654785, test loss:0.5955151319503784, test acc:0.845
Epoch:21, training loss:0.21087169647216797, test loss:0.6678590774536133, test acc:0.8216666666666667
Epoch:22, training loss:0.2691454589366913, test loss:0.6352696418762207, test acc:0.8316666666666667
Epoch:23, training loss:0.16838465631008148, test loss:0.5398358702659607, test acc:0.8311111111111111
Epoch:24, training loss:0.20525144040584564, test loss:0.7075311541557312, test acc:0.8077777777777778
Epoch:25, training loss:0.1619407832622528, test loss:0.6381714344024658, test acc:0.8294444444444444
Epoch:26, training loss:0.3186645805835724, test loss:0.6241326928138733, test acc:0.8316666666666667
Epoch:27, training loss:0.21727760136127472, test loss:0.5543980598449707, test acc:0.8422222222222222
Epoch:28, training loss:0.1516798585653305, test loss:0.7269392013549805, test acc:0.8044444444444444
Epoch:29, training loss:0.17817026376724243, test loss:0.9322314262390137, test acc:0.7994444444444444
Epoch:30, training loss:0.18726937472820282, test loss:0.615978479385376, test acc:0.8288888888888889
Epoch:31, training loss:0.16649626195430756, test loss:0.7975939512252808, test acc:0.8094444444444444
Epoch:32, training loss:0.15233896672725677, test loss:0.6973186135292053, test acc:0.8411111111111111
Epoch:33, training loss:0.17808915674686432, test loss:0.9127597808837891, test acc:0.7938888888888889
Epoch:34, training loss:0.1655980497598648, test loss:0.8677843809127808, test acc:0.8144444444444444
Epoch:35, training loss:0.13648580014705658, test loss:0.8527511358261108, test acc:0.8205555555555556
Epoch:36, training loss:0.23258914053440094, test loss:0.7444648146629333, test acc:0.8272222222222222
Epoch:37, training loss:0.11238671839237213, test loss:0.8697929978370667, test acc:0.8111111111111111
Epoch:38, training loss:0.1946997493505478, test loss:1.0479363203048706, test acc:0.7972222222222223
Epoch:39, training loss:0.07627975195646286, test loss:0.747904896736145, test acc:0.8261111111111111
Epoch:40, training loss:0.11844547092914581, test loss:0.7939317226409912, test acc:0.8205555555555556
Epoch:41, training loss:0.0793534368276596, test loss:0.8736403584480286, test acc:0.8361111111111111
Epoch:42, training loss:0.11218392848968506, test loss:1.0591646432876587, test acc:0.8155555555555556
Epoch:43, training loss:0.06385251134634018, test loss:0.9229589104652405, test acc:0.825
Epoch:44, training loss:0.07807348668575287, test loss:0.8753457069396973, test acc:0.8183333333333334
Epoch:45, training loss:0.08799095451831818, test loss:0.8436613082885742, test acc:0.8144444444444444
Epoch:46, training loss:0.1375098079442978, test loss:0.9797555208206177, test acc:0.8044444444444444
Epoch:47, training loss:0.06856043636798859, test loss:0.8567385077476501, test acc:0.815
Epoch:48, training loss:0.0773308128118515, test loss:1.18166184425354, test acc:0.7838888888888889
Epoch:49, training loss:0.05941254273056984, test loss:1.0213779211044312, test acc:0.8155555555555556
Epoch:50, training loss:0.1035490483045578, test loss:1.0756230354309082, test acc:0.8022222222222222
Epoch:51, training loss:0.09645117819309235, test loss:1.1936171054840088, test acc:0.785
Epoch:52, training loss:0.12326036393642426, test loss:1.2111790180206299, test acc:0.8144444444444444
Epoch:53, training loss:0.05958443135023117, test loss:1.1956232786178589, test acc:0.7916666666666666
Epoch:54, training loss:0.05399293452501297, test loss:1.0961178541183472, test acc:0.8177777777777778
Epoch:55, training loss:0.12647606432437897, test loss:1.6505606174468994, test acc:0.7816666666666666
Epoch:56, training loss:0.04330509528517723, test loss:1.0939319133758545, test acc:0.8288888888888889
Epoch:57, training loss:0.02525743469595909, test loss:1.4170854091644287, test acc:0.8133333333333334
Epoch:58, training loss:0.048123277723789215, test loss:1.3025751113891602, test acc:0.7988888888888889
Epoch:59, training loss:0.06338287889957428, test loss:1.225897192955017, test acc:0.8044444444444444
Epoch:60, training loss:0.04927503317594528, test loss:1.5709302425384521, test acc:0.7972222222222223
Epoch:61, training loss:0.07111257314682007, test loss:1.1290982961654663, test acc:0.8138888888888889
Epoch:62, training loss:0.026777219027280807, test loss:1.4395771026611328, test acc:0.8205555555555556
Epoch:63, training loss:0.05357850342988968, test loss:1.378814935684204, test acc:0.7955555555555556
Epoch:64, training loss:0.08600902557373047, test loss:1.2050187587738037, test acc:0.8261111111111111
Epoch:65, training loss:0.0345231369137764, test loss:1.5781947374343872, test acc:0.78
Epoch:66, training loss:0.06982888281345367, test loss:1.6556321382522583, test acc:0.7744444444444445
Epoch:67, training loss:0.05735455080866814, test loss:1.6874239444732666, test acc:0.8005555555555556
Epoch:68, training loss:0.024729464203119278, test loss:1.3248322010040283, test acc:0.81
Epoch:69, training loss:0.06211928650736809, test loss:1.675273060798645, test acc:0.8172222222222222
Epoch:70, training loss:0.07305227965116501, test loss:1.446093201637268, test acc:0.8016666666666666
Epoch:71, training loss:0.046461280435323715, test loss:1.5003855228424072, test acc:0.8016666666666666
Epoch:72, training loss:0.04970233887434006, test loss:1.5920898914337158, test acc:0.7872222222222223
Epoch:73, training loss:0.02306448109447956, test loss:1.6104457378387451, test acc:0.7916666666666666
Epoch:74, training loss:0.01983219012618065, test loss:1.5789024829864502, test acc:0.795
Epoch:75, training loss:0.03708440065383911, test loss:1.7485768795013428, test acc:0.78
Epoch:76, training loss:0.03739338740706444, test loss:1.5334972143173218, test acc:0.7988888888888889
Epoch:77, training loss:0.031062711030244827, test loss:2.394796848297119, test acc:0.7938888888888889
Epoch:78, training loss:0.022879749536514282, test loss:1.8464508056640625, test acc:0.8022222222222222
Epoch:79, training loss:0.023343900218605995, test loss:1.5882354974746704, test acc:0.7944444444444444
Epoch:80, training loss:0.042662374675273895, test loss:2.064602851867676, test acc:0.8016666666666666
Epoch:81, training loss:0.02380821295082569, test loss:1.5154410600662231, test acc:0.8161111111111111
Epoch:82, training loss:0.012200350873172283, test loss:2.1811399459838867, test acc:0.7794444444444445
Epoch:83, training loss:0.01166884507983923, test loss:1.4987916946411133, test acc:0.815
Epoch:84, training loss:0.009185520932078362, test loss:2.2845101356506348, test acc:0.79
Epoch:85, training loss:0.02334340661764145, test loss:1.8192442655563354, test acc:0.8116666666666666
Epoch:86, training loss:0.030281521379947662, test loss:1.5730282068252563, test acc:0.8133333333333334
Epoch:87, training loss:0.029011428356170654, test loss:1.812384843826294, test acc:0.79
Epoch:88, training loss:0.03167660906910896, test loss:2.3709189891815186, test acc:0.8094444444444444
Epoch:89, training loss:0.05701599642634392, test loss:2.1176013946533203, test acc:0.8166666666666667
Epoch:90, training loss:0.031241217628121376, test loss:1.6764276027679443, test acc:0.815
Epoch:91, training loss:0.014481841586530209, test loss:1.7162882089614868, test acc:0.8066666666666666
Epoch:92, training loss:0.0052954968996346, test loss:1.7485913038253784, test acc:0.8127777777777778
Epoch:93, training loss:0.02504597418010235, test loss:1.9195632934570312, test acc:0.7977777777777778
Epoch:94, training loss:0.001766901696100831, test loss:1.751115083694458, test acc:0.8
Epoch:95, training loss:0.002339094877243042, test loss:1.794144868850708, test acc:0.8088888888888889
Epoch:96, training loss:0.025817517191171646, test loss:2.3382582664489746, test acc:0.8022222222222222
Epoch:97, training loss:0.02110806107521057, test loss:1.9258594512939453, test acc:0.7916666666666666
Epoch:98, training loss:0.008112868294119835, test loss:1.748984456062317, test acc:0.8083333333333333
Epoch:99, training loss:0.0028439576271921396, test loss:1.8123271465301514, test acc:0.8127777777777778
Epoch:100, training loss:0.012695033103227615, test loss:2.5509419441223145, test acc:0.8055555555555556
Epoch:101, training loss:0.020454885438084602, test loss:2.0601000785827637, test acc:0.8161111111111111
Epoch:102, training loss:0.0028668551240116358, test loss:1.9348475933074951, test acc:0.8077777777777778
Epoch:103, training loss:0.026545822620391846, test loss:1.849686861038208, test acc:0.8122222222222222
Epoch:104, training loss:0.0213493499904871, test loss:2.262320041656494, test acc:0.7916666666666666
Epoch:105, training loss:0.007836277596652508, test loss:1.952212929725647, test acc:0.8016666666666666
Epoch:106, training loss:0.009939129464328289, test loss:2.1168277263641357, test acc:0.8094444444444444
Epoch:107, training loss:0.009311656467616558, test loss:2.3562426567077637, test acc:0.7788888888888889
Epoch:108, training loss:0.03130083903670311, test loss:1.9152390956878662, test acc:0.8111111111111111
Epoch:109, training loss:0.003907027654349804, test loss:1.9261119365692139, test acc:0.8155555555555556
Epoch:110, training loss:0.0069426801055669785, test loss:2.1113767623901367, test acc:0.8077777777777778
Epoch:111, training loss:0.015028651803731918, test loss:1.8337364196777344, test acc:0.8083333333333333
Epoch:112, training loss:0.0022328610066324472, test loss:2.296963691711426, test acc:0.7994444444444444
Epoch:113, training loss:0.0017885863780975342, test loss:1.9146945476531982, test acc:0.8122222222222222
Epoch:114, training loss:0.0031391005031764507, test loss:2.179011583328247, test acc:0.8255555555555556
Epoch:115, training loss:0.00940070953220129, test loss:2.556753158569336, test acc:0.8155555555555556
Epoch:116, training loss:0.004141141660511494, test loss:1.977069616317749, test acc:0.8127777777777778
Epoch:117, training loss:0.003492350224405527, test loss:2.296684503555298, test acc:0.8038888888888889
Epoch:118, training loss:0.010564815253019333, test loss:1.9991302490234375, test acc:0.8127777777777778
Epoch:119, training loss:0.006422624457627535, test loss:2.833153247833252, test acc:0.7994444444444444
Epoch:120, training loss:0.004448093939572573, test loss:2.4581985473632812, test acc:0.8011111111111111
Epoch:121, training loss:0.003953908570110798, test loss:2.283487319946289, test acc:0.8072222222222222
Epoch:122, training loss:0.0025566541589796543, test loss:2.2303080558776855, test acc:0.815
Epoch:123, training loss:0.0062664770521223545, test loss:2.18489670753479, test acc:0.8005555555555556
Epoch:124, training loss:0.002979015000164509, test loss:2.161558151245117, test acc:0.8072222222222222
Epoch:125, training loss:0.0006991412956267595, test loss:2.101256847381592, test acc:0.8027777777777778
Epoch:126, training loss:0.012014120817184448, test loss:2.4399614334106445, test acc:0.8027777777777778
Epoch:127, training loss:0.01367566641420126, test loss:2.122762441635132, test acc:0.7927777777777778
Epoch:128, training loss:0.003866789396852255, test loss:2.8729403018951416, test acc:0.8038888888888889
Epoch:129, training loss:0.0029242176096886396, test loss:2.1394753456115723, test acc:0.8161111111111111
Epoch:130, training loss:0.014406929723918438, test loss:2.462432384490967, test acc:0.8072222222222222
Epoch:131, training loss:0.025033386424183846, test loss:2.3909912109375, test acc:0.8
Epoch:132, training loss:0.0020676942076534033, test loss:1.990006446838379, test acc:0.8138888888888889
Epoch:133, training loss:0.0008372538140974939, test loss:2.1665658950805664, test acc:0.8122222222222222
Epoch:134, training loss:0.0003633384476415813, test loss:2.2550926208496094, test acc:0.8116666666666666
Epoch:135, training loss:0.00031737409881316125, test loss:2.281501531600952, test acc:0.8088888888888889
Epoch:136, training loss:0.00040345810703001916, test loss:2.3542308807373047, test acc:0.8172222222222222
Epoch:137, training loss:0.003845931263640523, test loss:2.2765958309173584, test acc:0.8211111111111111
Epoch:138, training loss:0.0027966005727648735, test loss:2.2865636348724365, test acc:0.8072222222222222
Epoch:139, training loss:0.002909294795244932, test loss:2.459251880645752, test acc:0.8027777777777778
Epoch:140, training loss:0.003315896959975362, test loss:3.201355457305908, test acc:0.7916666666666666
Epoch:141, training loss:0.02614787220954895, test loss:2.7708160877227783, test acc:0.7938888888888889
Epoch:142, training loss:0.024959836155176163, test loss:2.4471611976623535, test acc:0.8011111111111111
Epoch:143, training loss:0.01039210520684719, test loss:3.0786290168762207, test acc:0.8005555555555556
Epoch:144, training loss:0.0011307275854051113, test loss:2.7826948165893555, test acc:0.8144444444444444
Epoch:145, training loss:0.003714008955284953, test loss:2.912357807159424, test acc:0.8077777777777778
Epoch:146, training loss:0.0015612038550898433, test loss:2.4162042140960693, test acc:0.8088888888888889
Epoch:147, training loss:0.0008458036463707685, test loss:2.639838218688965, test acc:0.8083333333333333
Epoch:148, training loss:0.00019724093726836145, test loss:2.401167392730713, test acc:0.8077777777777778
Epoch:149, training loss:0.00036465891753323376, test loss:2.613079309463501, test acc:0.8061111111111111
Epoch:150, training loss:0.00015225776587612927, test loss:2.4662106037139893, test acc:0.8105555555555556
Epoch:151, training loss:0.009719420224428177, test loss:3.062725067138672, test acc:0.8
Epoch:152, training loss:0.001168668270111084, test loss:2.846688747406006, test acc:0.7872222222222223
Epoch:153, training loss:0.004514251835644245, test loss:3.671264410018921, test acc:0.7833333333333333
Epoch:154, training loss:0.0029582036659121513, test loss:2.8053362369537354, test acc:0.7927777777777778
Epoch:155, training loss:0.001715501886792481, test loss:3.095508337020874, test acc:0.8016666666666666
Epoch:156, training loss:0.003118455410003662, test loss:2.860288619995117, test acc:0.8105555555555556
Epoch:157, training loss:0.0017507156589999795, test loss:3.638383150100708, test acc:0.795
Epoch:158, training loss:0.00015048339264467359, test loss:2.5348870754241943, test acc:0.8105555555555556
Epoch:159, training loss:0.00021327458671294153, test loss:3.3161797523498535, test acc:0.8055555555555556
Epoch:160, training loss:0.00014075636863708496, test loss:3.3636322021484375, test acc:0.8111111111111111
Epoch:161, training loss:7.232336065499112e-05, test loss:2.661097526550293, test acc:0.8111111111111111
Epoch:162, training loss:6.763063720427454e-05, test loss:3.6183323860168457, test acc:0.8061111111111111
Epoch:163, training loss:2.7745962142944336e-05, test loss:2.656672477722168, test acc:0.8083333333333333
Epoch:164, training loss:9.466134360991418e-05, test loss:2.744955062866211, test acc:0.8111111111111111
Epoch:165, training loss:0.08346479386091232, test loss:2.6934540271759033, test acc:0.7988888888888889
Epoch:166, training loss:0.0071344939060509205, test loss:2.7650437355041504, test acc:0.815
Epoch:167, training loss:0.0006053126999177039, test loss:3.4569156169891357, test acc:0.8094444444444444
Epoch:168, training loss:0.0013540616491809487, test loss:2.8906052112579346, test acc:0.795
Epoch:169, training loss:0.000723851437214762, test loss:3.2809367179870605, test acc:0.7944444444444444
Epoch:170, training loss:9.117791341850534e-05, test loss:2.989950180053711, test acc:0.8038888888888889
Epoch:171, training loss:0.010320058092474937, test loss:2.6316375732421875, test acc:0.8038888888888889
Epoch:172, training loss:0.004153017420321703, test loss:2.823610782623291, test acc:0.7927777777777778
Epoch:173, training loss:0.005749077536165714, test loss:2.9555273056030273, test acc:0.8005555555555556
Epoch:174, training loss:0.006586003117263317, test loss:2.604428291320801, test acc:0.7977777777777778
Epoch:175, training loss:0.00020951491023879498, test loss:3.0480542182922363, test acc:0.8077777777777778
Epoch:176, training loss:0.00026687749777920544, test loss:2.547882556915283, test acc:0.8061111111111111
Epoch:177, training loss:3.2067298889160156e-05, test loss:2.552432060241699, test acc:0.8055555555555556
Epoch:178, training loss:0.000117909446998965, test loss:3.3286235332489014, test acc:0.805
Epoch:179, training loss:2.1002613721066155e-05, test loss:3.0162124633789062, test acc:0.8055555555555556
Epoch:180, training loss:3.14895914925728e-05, test loss:3.023421287536621, test acc:0.8055555555555556
Epoch:181, training loss:3.903531251125969e-05, test loss:3.485586404800415, test acc:0.8066666666666666
Epoch:182, training loss:2.740782110777218e-05, test loss:2.65565824508667, test acc:0.8055555555555556
Epoch:183, training loss:0.013556836172938347, test loss:3.2645795345306396, test acc:0.7766666666666666
Epoch:184, training loss:0.003168004099279642, test loss:3.852555751800537, test acc:0.7894444444444444
Epoch:185, training loss:0.0012599562760442495, test loss:2.9286389350891113, test acc:0.805
Epoch:186, training loss:0.00023388977569993585, test loss:2.6072089672088623, test acc:0.8105555555555556
Epoch:187, training loss:9.905718616209924e-05, test loss:2.651201009750366, test acc:0.8133333333333334
Epoch:188, training loss:8.62570886965841e-05, test loss:2.6335418224334717, test acc:0.8111111111111111
Epoch:189, training loss:2.6773373974720016e-05, test loss:2.6534078121185303, test acc:0.8105555555555556
Begin training
Epoch:1, training loss:2.127981424331665, test loss:1.9822990894317627, test acc:0.4627777777777778
Epoch:2, training loss:1.002932071685791, test loss:0.8707643747329712, test acc:0.7216666666666667
Epoch:3, training loss:0.6216510534286499, test loss:0.72983717918396, test acc:0.7611111111111111
Epoch:4, training loss:0.7031125426292419, test loss:0.7042298316955566, test acc:0.7683333333333333
Epoch:5, training loss:0.5438759922981262, test loss:0.826348066329956, test acc:0.7411111111111112
Epoch:6, training loss:0.5348427295684814, test loss:0.5421501398086548, test acc:0.82
Epoch:7, training loss:0.43356990814208984, test loss:0.5533835291862488, test acc:0.8416666666666667
Epoch:8, training loss:0.5100880265235901, test loss:0.46563777327537537, test acc:0.8494444444444444
Epoch:9, training loss:0.35724812746047974, test loss:0.5662522912025452, test acc:0.8505555555555555
Epoch:10, training loss:0.5488288402557373, test loss:0.5353754162788391, test acc:0.8333333333333334
Begin training
Epoch:1, training loss:2.070554256439209, test loss:1.9231559038162231, test acc:0.5494444444444444
Epoch:2, training loss:0.9836909174919128, test loss:0.8864968419075012, test acc:0.7094444444444444
Epoch:3, training loss:0.5317575931549072, test loss:0.7566863894462585, test acc:0.7544444444444445
Epoch:4, training loss:0.6922000050544739, test loss:0.673703134059906, test acc:0.7783333333333333
Begin training
Epoch:1, training loss:1.976158857345581, test loss:1.8001973628997803, test acc:0.59
Epoch:2, training loss:0.9486685395240784, test loss:0.8250449895858765, test acc:0.7205555555555555
Epoch:3, training loss:0.6386885046958923, test loss:0.5734907984733582, test acc:0.7994444444444444
Epoch:4, training loss:0.5924125909805298, test loss:0.6112298369407654, test acc:0.7944444444444444
Epoch:5, training loss:0.601983368396759, test loss:0.6914119720458984, test acc:0.7861111111111111
Epoch:6, training loss:0.44910547137260437, test loss:0.583903968334198, test acc:0.8383333333333334
Epoch:7, training loss:0.5446842908859253, test loss:0.5875369906425476, test acc:0.8205555555555556
Epoch:8, training loss:0.4129667282104492, test loss:0.5376126766204834, test acc:0.8372222222222222
Epoch:9, training loss:0.4547349214553833, test loss:0.44202470779418945, test acc:0.8611111111111112
Epoch:10, training loss:0.4187551736831665, test loss:0.44034814834594727, test acc:0.8644444444444445
Epoch:11, training loss:0.34336453676223755, test loss:0.5068928599357605, test acc:0.8627777777777778
Epoch:12, training loss:0.389649361371994, test loss:0.4549288749694824, test acc:0.8405555555555555
Epoch:13, training loss:0.3394712209701538, test loss:0.6595619916915894, test acc:0.7955555555555556
Epoch:14, training loss:0.35093382000923157, test loss:0.6156104803085327, test acc:0.82
Epoch:15, training loss:0.25247666239738464, test loss:0.46506279706954956, test acc:0.8505555555555555
Epoch:16, training loss:0.3441055715084076, test loss:0.44750040769577026, test acc:0.8644444444444445
Epoch:17, training loss:0.26694196462631226, test loss:0.6532646417617798, test acc:0.825
Epoch:18, training loss:0.21886947751045227, test loss:0.6810760498046875, test acc:0.84
Epoch:19, training loss:0.20160159468650818, test loss:0.5422148704528809, test acc:0.8572222222222222
Epoch:20, training loss:0.18614378571510315, test loss:0.6514822244644165, test acc:0.8111111111111111
Epoch:21, training loss:0.2408713400363922, test loss:1.0714375972747803, test acc:0.7711111111111111
Epoch:22, training loss:0.2023407369852066, test loss:0.592022716999054, test acc:0.8361111111111111
Epoch:23, training loss:0.23974040150642395, test loss:0.6969698071479797, test acc:0.7966666666666666
Epoch:24, training loss:0.22252371907234192, test loss:0.6750977635383606, test acc:0.8283333333333334
Epoch:25, training loss:0.19739562273025513, test loss:0.9337549209594727, test acc:0.7961111111111111
Epoch:26, training loss:0.19939717650413513, test loss:0.6627696752548218, test acc:0.8227777777777778
Epoch:27, training loss:0.1439584642648697, test loss:0.8980467319488525, test acc:0.8394444444444444
Epoch:28, training loss:0.20132197439670563, test loss:0.7695198059082031, test acc:0.8027777777777778
Epoch:29, training loss:0.08508629351854324, test loss:0.9933372735977173, test acc:0.8066666666666666
Epoch:30, training loss:0.16778257489204407, test loss:1.092284917831421, test acc:0.7738888888888888
Epoch:31, training loss:0.1470947116613388, test loss:0.7512735724449158, test acc:0.8244444444444444
Epoch:32, training loss:0.15311458706855774, test loss:0.6505638360977173, test acc:0.8422222222222222
Epoch:33, training loss:0.14196909964084625, test loss:0.9998210072517395, test acc:0.8183333333333334
Epoch:34, training loss:0.15599526464939117, test loss:0.8001513481140137, test acc:0.8111111111111111
Epoch:35, training loss:0.18947698175907135, test loss:0.7555795311927795, test acc:0.8155555555555556
Epoch:36, training loss:0.20782004296779633, test loss:1.0974690914154053, test acc:0.7661111111111111
Epoch:37, training loss:0.15462476015090942, test loss:0.8251840472221375, test acc:0.8177777777777778
Epoch:38, training loss:0.1527840942144394, test loss:0.9814551472663879, test acc:0.7777777777777778
Epoch:39, training loss:0.10100197792053223, test loss:0.9672199487686157, test acc:0.8083333333333333
Epoch:40, training loss:0.15839046239852905, test loss:0.941270112991333, test acc:0.8138888888888889
Epoch:41, training loss:0.10724738985300064, test loss:0.9815170168876648, test acc:0.8105555555555556
Epoch:42, training loss:0.09746312350034714, test loss:0.8888331651687622, test acc:0.8094444444444444
Epoch:43, training loss:0.08999025821685791, test loss:0.9914926290512085, test acc:0.8088888888888889
Epoch:44, training loss:0.09160001575946808, test loss:1.095604658126831, test acc:0.8133333333333334
Epoch:45, training loss:0.07759357243776321, test loss:1.334177851676941, test acc:0.8172222222222222
Epoch:46, training loss:0.12914295494556427, test loss:1.284584641456604, test acc:0.7872222222222223
Epoch:47, training loss:0.06558778882026672, test loss:1.1914417743682861, test acc:0.7983333333333333
Epoch:48, training loss:0.07679247111082077, test loss:1.0230193138122559, test acc:0.8138888888888889
Epoch:49, training loss:0.07305507361888885, test loss:1.0864804983139038, test acc:0.8105555555555556
Epoch:50, training loss:0.09112982451915741, test loss:1.0001459121704102, test acc:0.8166666666666667
Epoch:51, training loss:0.1380583941936493, test loss:1.4202793836593628, test acc:0.7805555555555556
Epoch:52, training loss:0.045313697308301926, test loss:1.028780221939087, test acc:0.8194444444444444
Epoch:53, training loss:0.08544567972421646, test loss:1.1059908866882324, test acc:0.8033333333333333
Epoch:54, training loss:0.04040930047631264, test loss:0.9779554009437561, test acc:0.8277777777777777
Epoch:55, training loss:0.023649858310818672, test loss:1.2001543045043945, test acc:0.8111111111111111
Epoch:56, training loss:0.07812751829624176, test loss:1.4162477254867554, test acc:0.7961111111111111
Epoch:57, training loss:0.09377006441354752, test loss:1.3470888137817383, test acc:0.8072222222222222
Epoch:58, training loss:0.05005550757050514, test loss:1.5867106914520264, test acc:0.7872222222222223
Epoch:59, training loss:0.045985184609889984, test loss:2.115924596786499, test acc:0.7877777777777778
Epoch:60, training loss:0.053480587899684906, test loss:1.2394882440567017, test acc:0.8105555555555556
Epoch:61, training loss:0.03552792966365814, test loss:1.3196107149124146, test acc:0.8161111111111111
Epoch:62, training loss:0.06485109031200409, test loss:1.3618522882461548, test acc:0.8016666666666666
Epoch:63, training loss:0.07965876162052155, test loss:1.2727837562561035, test acc:0.8172222222222222
Epoch:64, training loss:0.0810040682554245, test loss:1.7722711563110352, test acc:0.7822222222222223
Epoch:65, training loss:0.03012068197131157, test loss:1.5387715101242065, test acc:0.8116666666666666
Epoch:66, training loss:0.024823900312185287, test loss:1.7643786668777466, test acc:0.815
Epoch:67, training loss:0.04003388062119484, test loss:1.7087242603302002, test acc:0.7977777777777778
Epoch:68, training loss:0.010024657472968102, test loss:1.5003398656845093, test acc:0.8022222222222222
Epoch:69, training loss:0.057286977767944336, test loss:1.6126599311828613, test acc:0.8066666666666666
Epoch:70, training loss:0.04578041657805443, test loss:1.6756987571716309, test acc:0.7911111111111111
Epoch:71, training loss:0.021320195868611336, test loss:1.401347279548645, test acc:0.8161111111111111
Epoch:72, training loss:0.10311964154243469, test loss:2.0185532569885254, test acc:0.7983333333333333
Epoch:73, training loss:0.01182100735604763, test loss:2.2172040939331055, test acc:0.785
Epoch:74, training loss:0.035623837262392044, test loss:1.8396995067596436, test acc:0.7938888888888889
Epoch:75, training loss:0.022383468225598335, test loss:1.8488883972167969, test acc:0.8011111111111111
Epoch:76, training loss:0.051457855850458145, test loss:2.4874958992004395, test acc:0.7977777777777778
Epoch:77, training loss:0.054607126861810684, test loss:1.609919548034668, test acc:0.8072222222222222
Epoch:78, training loss:0.048453815281391144, test loss:2.1557374000549316, test acc:0.8122222222222222
Epoch:79, training loss:0.06915713846683502, test loss:1.7598001956939697, test acc:0.7955555555555556
Epoch:80, training loss:0.01952875778079033, test loss:2.00335693359375, test acc:0.7944444444444444
Epoch:81, training loss:0.01745644398033619, test loss:1.7130422592163086, test acc:0.7988888888888889
Epoch:82, training loss:0.050580739974975586, test loss:1.8156589269638062, test acc:0.8055555555555556
Epoch:83, training loss:0.02084225043654442, test loss:1.7272908687591553, test acc:0.8022222222222222
Epoch:84, training loss:0.006620415020734072, test loss:2.0369601249694824, test acc:0.7972222222222223
Epoch:85, training loss:0.03586512431502342, test loss:1.8260939121246338, test acc:0.8122222222222222
Epoch:86, training loss:0.03311487287282944, test loss:1.8310600519180298, test acc:0.7911111111111111
Epoch:87, training loss:0.040592823177576065, test loss:1.7514992952346802, test acc:0.7961111111111111
Epoch:88, training loss:0.011993820779025555, test loss:1.886409044265747, test acc:0.815
Epoch:89, training loss:0.04935270920395851, test loss:1.8229622840881348, test acc:0.7916666666666666
Epoch:90, training loss:0.005483222659677267, test loss:1.5811446905136108, test acc:0.8177777777777778
Epoch:91, training loss:0.04956969991326332, test loss:1.8808753490447998, test acc:0.8011111111111111
Epoch:92, training loss:0.09920930117368698, test loss:1.7774310111999512, test acc:0.8116666666666666
Epoch:93, training loss:0.027198277413845062, test loss:1.6030564308166504, test acc:0.8111111111111111
Epoch:94, training loss:0.0056475987657904625, test loss:1.949633240699768, test acc:0.8133333333333334
Epoch:95, training loss:0.027176912873983383, test loss:1.8134750127792358, test acc:0.8088888888888889
Epoch:96, training loss:0.043651681393384933, test loss:1.8562206029891968, test acc:0.825
Epoch:97, training loss:0.005066182930022478, test loss:1.8029108047485352, test acc:0.8133333333333334
Epoch:98, training loss:0.018946299329400063, test loss:1.9087936878204346, test acc:0.7988888888888889
Epoch:99, training loss:0.0032958686351776123, test loss:1.792257308959961, test acc:0.8083333333333333
Epoch:100, training loss:0.0029276679269969463, test loss:3.355454683303833, test acc:0.8266666666666667
Epoch:101, training loss:0.02875576727092266, test loss:1.9898067712783813, test acc:0.8172222222222222
Epoch:102, training loss:0.0029081047978252172, test loss:1.8764111995697021, test acc:0.815
Epoch:103, training loss:0.006056428886950016, test loss:2.625443935394287, test acc:0.8277777777777777
Epoch:104, training loss:0.005810759495943785, test loss:2.087728977203369, test acc:0.8044444444444444
Epoch:105, training loss:0.0018508858047425747, test loss:2.2936038970947266, test acc:0.8144444444444444
Epoch:106, training loss:0.03940125182271004, test loss:3.050675868988037, test acc:0.7838888888888889
Epoch:107, training loss:0.020190294831991196, test loss:2.4139583110809326, test acc:0.8
Epoch:108, training loss:0.005589663051068783, test loss:2.370009422302246, test acc:0.8033333333333333
Epoch:109, training loss:0.008346321061253548, test loss:2.1249735355377197, test acc:0.7994444444444444
Epoch:110, training loss:0.005836792755872011, test loss:2.172085762023926, test acc:0.7811111111111111
Epoch:111, training loss:0.012030904181301594, test loss:2.675750494003296, test acc:0.7922222222222223
Epoch:112, training loss:0.08348110318183899, test loss:2.865640878677368, test acc:0.7788888888888889
Epoch:113, training loss:0.014269441366195679, test loss:1.9728670120239258, test acc:0.7961111111111111
Epoch:114, training loss:0.0030053327791392803, test loss:2.7916409969329834, test acc:0.8094444444444444
Epoch:115, training loss:0.0075397309847176075, test loss:3.03672456741333, test acc:0.8111111111111111
Epoch:116, training loss:0.006367581430822611, test loss:2.950590133666992, test acc:0.8072222222222222
Epoch:117, training loss:0.022504810243844986, test loss:1.8473048210144043, test acc:0.8277777777777777
Epoch:118, training loss:0.028992541134357452, test loss:2.185316562652588, test acc:0.8066666666666666
Epoch:119, training loss:0.028699340298771858, test loss:2.5058529376983643, test acc:0.8044444444444444
Epoch:120, training loss:0.034598514437675476, test loss:2.252603769302368, test acc:0.7888888888888889
Epoch:121, training loss:0.005174675956368446, test loss:2.4496653079986572, test acc:0.8044444444444444
Epoch:122, training loss:0.0011017069919034839, test loss:2.181436061859131, test acc:0.8116666666666666
Epoch:123, training loss:0.0023957800585776567, test loss:2.357745409011841, test acc:0.8111111111111111
Epoch:124, training loss:0.02986404486000538, test loss:2.6095833778381348, test acc:0.8133333333333334
